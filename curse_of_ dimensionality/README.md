# Curse of Dimensionality:         
        
        Dimensions means features.
        Working with low feature data is not efficient.
        And having large number of features is sometimes a problem.
        We require optimal number features for the model.

        Higher dimensional data is not good for the machine learning model as it creates sparsity. Because after a certain point it is difficult to work in higher dimensional space for ml model.

        So we do dimensionality reduction. 
        We can use the following techniques

        A) Feature Selection 
            1. Forward Selection
            2. Backward Selection

        B) Feature Extraction
            1. Principal Component Analysis (PCA)   
            2. Linear Discriminant Analysis (LDA)
            3. Tsne

        ![alt text](C:\Users\Aditya\Pictures\Screenshots\Screenshot 2025-01-14 151056.png "hmm")