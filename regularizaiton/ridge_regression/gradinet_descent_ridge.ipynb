{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At first we will use SGDRegressor from the sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = SGDRegressor(penalty = 'l2', alpha = 0.001, max_iter = 500, eta0=0.1, learning_rate='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score :  0.4469406471517511\n",
      "[  33.32573848 -110.59272726  386.62576311  266.27624593  -10.12925457\n",
      "  -67.8967586  -167.9819519   105.80298493  354.34637264  102.64998306]\n",
      "[153.193574]\n"
     ]
    }
   ],
   "source": [
    "reg1.fit(x_train, y_train)\n",
    "pred1 = reg1.predict(x_test)\n",
    "print(\"R2 score : \", r2_score(y_test, pred1))\n",
    "print(reg1.coef_)\n",
    "print(reg1.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second we will use Ridge from the sklearn by adjusting its parameter for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = Ridge(solver='saga', max_iter = 500, alpha = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look on the results of Ridge which somewhat differ from the results of SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score :  0.4408754071205436\n",
      "[  -8.75651924 -204.2917832   518.42584893  339.95926418 -785.48863324\n",
      "  473.52797274  105.81340424  114.34641699  818.9180828    52.87710294]\n",
      "151.88536365993718\n"
     ]
    }
   ],
   "source": [
    "reg2.fit(x_train, y_train)\n",
    "pred2 = reg2.predict(x_test)\n",
    "print(\"R2 score : \", r2_score(y_test, pred2))\n",
    "print(reg2.coef_)\n",
    "print(reg2.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we will create our own class for the implementation of Ridge regression using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_ridge:\n",
    "    def __init__(self, alpha, max_iter, learning_rate):\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.intercept = None\n",
    "        self.coeff = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        # Initialize coefficients and intercept\n",
    "        self.coeff = np.ones(x_train.shape[1])\n",
    "        self.intercept = 0\n",
    "\n",
    "        # Combine intercept and coefficients into a single weight vector\n",
    "        w = np.insert(self.coeff, 0, self.intercept)\n",
    "\n",
    "        # Add a bias column to x_train\n",
    "        x_train = np.insert(x_train, 0, 1, axis=1)\n",
    "\n",
    "        # Gradient descent loop\n",
    "        for i in range(self.max_iter):\n",
    "            predictions = np.dot(x_train, w)\n",
    "            errors = predictions - y_train\n",
    "            # Compute the gradient\n",
    "            derivative = (2 / x_train.shape[0]) * (np.dot(x_train.T, errors) + self.alpha * np.insert(w[1:], 0, 0))\n",
    "            # Update weights\n",
    "            w -= self.learning_rate * derivative\n",
    "\n",
    "        # Update intercept and coefficients\n",
    "        self.intercept = w[0]\n",
    "        self.coeff = w[1:]\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        # Predict using the learned coefficients\n",
    "        return np.dot(x_test, self.coeff) + self.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg3 = my_ridge(alpha = 0.001, max_iter = 500 , learning_rate = 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the difference between the results of prebuilt function and the results form the funciton that we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_socre :  0.4408753177579804\n",
      "[ 5.04690153  1.68893578 11.41410258  9.26005258  4.70974156  3.75551296\n",
      " -5.54854704  7.87508898 11.54627214  7.36571964]\n",
      "149.5404868004467\n"
     ]
    }
   ],
   "source": [
    "reg3.fit(x_train, y_train)\n",
    "pred3 = reg2.predict(x_test)\n",
    "print(\"R2_socre : \", r2_score(y_test, pred3))\n",
    "print(reg3.coeff)\n",
    "print(reg3.intercept)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
